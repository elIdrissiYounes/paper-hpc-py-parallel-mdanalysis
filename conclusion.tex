\label{concl}
There are currently many freely available libraries for the analysis and processing of three-dimensional time series.
However, dramatic increases in the size of trajectories combined with the serial nature of these libraries necessitates 
use of state of the art high performance computing tools for rapid analysis of these time series. 

We have been able to identify the root cause for stragglers in our MPI test case and our data suggest a \textbf{new specific hypothesis}. 
We tested our benchmark on RMSD (I/O bound) and Dihedral featurization (compute bound) algorithms in \package{MDAnalysis}.
Both communication and I/O appeared to be the scalability bottleneck for our RMSD benchmark test case when using a shared file.

In fact, for I/O-bound workload, \emph{stragglers are due to the competition between MPI and the Lustre file system on the shared Infini-band interconnect}. 
This hypothesis appears to be consistent with the observation that for larger number of process counts, communication is primarily a problem in
the presence of many I/O requests produced by I/O-bound workloads.
In fact, communication time \tcomm, i.e., the \texttt{mpi4py.MPI.COMM\_WORLD.Gather()} step, could take
much longer for stragglers than for ``normal'' MPI ranks when I/O has to be performed through a shared trajectory file (Figure \ref{fig:MPIranks}). 

The ratio between compute load and I/O load appeared to be crucial as well. 
For sufficiently large per-frame workloads, close to ideal scaling was achievable (Figure \ref{fig:MPI-dihedral-comm}). 
Additionally, the effect of communication was less pronounced when the work became more compute-bound.
This is because with compute-bound tasks there is less competition over accessing the shared trajectory file.

For I/O bound tasks we needed to come up with solution to overcome stragglers. 
We were able to achieve much better performance in our RMSD benchmark when we used global array toolkit instead of message-passing interface for communication. 
Using global array, we did not observe any delayed task due to communication (Figure \ref{fig:MPIwithIO-ga4py}) and it significantly reduces the communication cost. 

However, reducing communication cost was not enough for achieving near ideal scaling.
We were able to improve I/O through splitting the shared trajectory file and parallel I/O (Figures \ref{fig:MPIwithIO-split} and \ref{fig:MPIwithIO-hdf5}). 
In both cases we were able to achieve near ideal scaling.
With splitting the trajectories, effect of communication is still apparent on the performance; however we could tackle this problem using 
global array toolkit (Compare Figure \ref{fig:MPIwithIO-split} to Figure \ref{fig:MPIwithIO-split-ga}).

All the above strategies, provides the bio-molecular simulation community the means to perform a wide variety of parallel analyses on data generated from computational simulations.
The guidelines provided in the present study, help people to tackle their problem depending on the workload being I/O bound or compute bound. 
The analysis indicates that splitting the trajectories in combination with global array or parallel I/O will make it feasible to run a I/O bound task on scalable computers up to 8 nodes and achieve near ideal scaling behavior.